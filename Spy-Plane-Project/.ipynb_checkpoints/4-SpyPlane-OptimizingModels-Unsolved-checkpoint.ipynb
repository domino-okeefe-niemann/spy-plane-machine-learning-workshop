{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Models\n",
    "\n",
    "This notebook pulls in the model from the SpyPlane-RandomForestClassifier.ipynb notebook and optimizes the random forest model created there.\n",
    "\n",
    "This projects is based off the Buzzfeed news article on identifying spy planes found [here](https://www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes), using the data and code adapted from their github repository [here](https://github.com/BuzzFeedNews/2017-08-spy-plane-finder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Follow the directions in any cell that does not contain code. If a cell does contain code, run this before moving on to the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#import packages\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#sci-kit learn is a library with machine learning algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data and Train Model\n",
    "\n",
    "Repeat the data formatting steps from the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This relies on output from a previous notebook!\n",
    "# If this cell does not work, try using the pregenerated data instead\n",
    "#planes_labeled = pd.read_csv(\"/mnt/data/spyplane-data/pregenerated_planes_labeled.csv\")\n",
    "planes_labeled = pd.read_csv(\"/mnt/data/spyplane-data/planes_labeled.csv\")\n",
    "\n",
    "#format data by removing non-numeric columnns and factorize the class\n",
    "X = planes_labeled.drop(['adshex','class', 'type'], axis = 1)\n",
    "y = pd.factorize(planes_labeled['class'])[0]\n",
    "\n",
    "#split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "Hyperparameters can be thought of as the settings of an algorithm that can be adjusted to optimize performance. These are something you will set before training the model. You are unlikely to know what the best settings for these will be ahead of time, and tuning a model is where machine learning turns from a science into trial-and-error based engineering.\n",
    "\n",
    "In the case of a random forest, hyperparameters include the number of decision trees in the forest and the number of features considered by each tree when splitting a node. Scikit-Learn implements default hyperparameters for all models, but these are not guaranteed to be optimal for a problem. \n",
    "\n",
    "Below, we can see the default parameters that were used in our above model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the effects of altering hyperparameters by increasing the number of estimators (a.k.a the number of decision trees) on the compute time, precision, and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#try model with different parameter for number of trees (default of 10)\n",
    "np.random.seed(415)\n",
    "spy_model = RandomForestClassifier(n_estimators = 10)\n",
    "spy_model.fit(X_train,y_train)\n",
    "\n",
    "#calculate predictions on test set\n",
    "predictions = spy_model.predict(X_test)\n",
    "\n",
    "#metrics\n",
    "precision = metrics.precision_score(y_true = y_test, y_pred = predictions)\n",
    "recall = metrics.recall_score(y_true = y_test, y_pred = predictions)\n",
    "accuracy = metrics.accuracy_score(y_true = y_test, y_pred = predictions)\n",
    "print('Precision: ' + str(precision) + ' Recall: ' + str(recall) + \n",
    "      ' Accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#try model with different parameter for number of trees (100)\n",
    "np.random.seed(415)\n",
    "model_higher_n = RandomForestClassifier(n_estimators = 100)\n",
    "model_higher_n.fit(X_train,y_train)\n",
    "\n",
    "#calculate predictions on test set\n",
    "predictions_higher_n = model_higher_n.predict(X_test)\n",
    "\n",
    "#metrics\n",
    "precision_higher_n = metrics.precision_score(y_true = y_test, y_pred = predictions_higher_n)\n",
    "recall_higher_n = metrics.recall_score(y_true = y_test, y_pred = predictions_higher_n)\n",
    "accuracy_higher_n = metrics.accuracy_score(y_true = y_test, y_pred = predictions_higher_n)\n",
    "print('Precision: ' + str(precision_higher_n) + ' Recall: ' + str(recall_higher_n) + \n",
    "      ' Accuracy: ' + str(accuracy_higher_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_model = RandomForestClassifier(n_estimators = 10)\n",
    "print('Parameters currently in use:\\n')\n",
    "print(spy_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few commonly adjusted hyperparameters of random forests (See this [article](https://medium.com/@ODSC/optimizing-hyperparameters-for-random-forest-algorithms-in-scikit-learn-d60b7aa07ead) for more detail):\n",
    "\n",
    "- `n_estimators`: Random forest models are ensembles of decision trees. N_estimators controls the number of decision trees used in the model.\n",
    "     \n",
    "     \n",
    "- `max_features`: Random forest models randomly resample features prior to determining the best split. This determines the number of features to resample. \n",
    "\n",
    "\n",
    "- `max_depth`: Each tree in the random forest model makes multiple splits to isolate homogeneous groups of outcomes. Max_depth determines the max number of levels. \n",
    "\n",
    "\n",
    "- `min_samples_split`: Controls the minimum number of samples required to split each node. \n",
    "\n",
    "\n",
    "- `min_samples_leaf`: Much like stopping the growth of trees once a minimum number of samples per split is reached, we can set the minimum number of samples required for each leaf. \n",
    "    \n",
    "    \n",
    "- `bootstrap`: method for sampling data points (with or without replacement)\n",
    "\n",
    "\n",
    "- `class_weight`: Weights associated with classes. The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity - Hyperparameter optimization\n",
    "\n",
    "Pick a metric and see if you can find the hyperparameters that optimize this. Feel free to use google to research the above hyperparameters as well as others that are used in Random Forest Classifiers. Official documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "**Spoiler Alert: Don't scroll below this section in the notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "########################################################\n",
    "#fill in the hyperparameter value(s) you'd like to try - feel free to add others\n",
    "n_estimators = 5\n",
    "max_depth = 5\n",
    "max_features = 'sqrt'\n",
    "min_samples_split = 10\n",
    "bootstrap = False\n",
    "class_weight = 'none'\n",
    "########################################################\n",
    "\n",
    "#create and fit model with your chosen hyperparameter values\n",
    "np.random.seed(415)\n",
    "your_model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features, \n",
    "                               min_samples_split=min_samples_split, bootstrap=bootstrap)\n",
    "your_model.fit(X_train,y_train)\n",
    "\n",
    "#calculate predictions on test set\n",
    "your_predictions = your_model.predict(X_test)\n",
    "\n",
    "#metrics\n",
    "your_precision = metrics.precision_score(y_true = y_test, y_pred = your_predictions)\n",
    "your_recall = metrics.recall_score(y_true = y_test, y_pred = your_predictions)\n",
    "your_accuracy = metrics.accuracy_score(y_true = y_test, y_pred = your_predictions)\n",
    "your_f1_score = metrics.f1_score(y_true = y_test, y_pred = your_predictions)\n",
    "\n",
    "print('Accuracy: ' + str(round(your_accuracy,4)) + '\\nPrecision: ' + str(round(your_precision,4)) + ', Recall: ' + str(round(your_recall,4)) + '\\n\\nF1 Score: '  + str(round(your_f1_score,6)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Result to Leaderboard\n",
    "\n",
    "#### When you are happy with your model, run the following cell to submit your result to the leaderboard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.client import Config\n",
    "\n",
    "user = os.environ['DOMINO_STARTING_USERNAME']\n",
    "\n",
    "score_dict = {'user':[user,],\n",
    "        'f1':[your_f1_score,], 'precision':[your_precision,], 'recall':[your_recall,],\n",
    "        'n_estimators':[n_estimators,], 'max_depth':[max_depth,], 'max_features':[max_features,], \n",
    "        'min_samples_split':[min_samples_split,], 'bootstrap':[bootstrap,], 'class_weight':[class_weight,]\n",
    "       }\n",
    "\n",
    "filename = user + '.csv'\n",
    "pd.DataFrame(score_dict, index=[0,]).to_csv(filename, index=False)\n",
    "    \n",
    "time.sleep(0.5)\n",
    "\n",
    "client = boto3.client('s3', aws_access_key_id='', aws_secret_access_key='')\n",
    "client._request_signer.sign = (lambda *args, **kwargs: None)\n",
    "\n",
    "client.upload_file(user + \".csv\", \"workshop-leaderboard\", \"lm-workshop/\" + user + \".csv\")\n",
    "\n",
    "print(\"Data upload succesfully\")\n",
    "pd.read_csv(filename).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spoilers below\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    ".\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search Cross Validation\n",
    "\n",
    "To check different values for these hyperparameters, we can use scikit-learn’s “RandomizedSearchCV” to define a grid of hyperparameter ranges and randomly sample from the grid, performing cross validation with each combination of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1000, stop = 3000, num = 200)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt', 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "#Weights associated with classes, The “balanced” mode uses the values of y to automatically adjust weights \n",
    "#inversely proportional to class frequencies\n",
    "class_weight=['balanced',None]\n",
    "# Create the random grid\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'class_weight':class_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "np.random.seed(415)\n",
    "model = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "model_rgs = RandomizedSearchCV(estimator = model, param_distributions = random_grid, scoring = 'recall',\n",
    "                               n_iter = 15, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "model_rgs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at randomized search best parameters\n",
    "model_rgs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model based on the hyperparameters from the above grid search\n",
    "np.random.seed(415)\n",
    "model_tuned = RandomForestClassifier(**model_rgs.best_params_)\n",
    "model_tuned.fit(X_train, y_train)\n",
    "\n",
    "predictions_tuned = model_tuned.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "precision_rgs = metrics.precision_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "recall_rgs = metrics.recall_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "accuracy_rgs = metrics.accuracy_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "print('Randomized Grid Search Metrics: Precision: ' + str(precision_rgs) + ' Recall: ' + str(recall_rgs) + \n",
    "      ' Accuracy: ' + str(accuracy_rgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "We'll look at the importance of different features in the data set on our predictions and make a visualization of these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make lists of the features (column names) and the feature importances returned from our model\n",
    "features = X.columns\n",
    "importances = list(model_tuned.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine the names and importances and sort\n",
    "feature_importance = list(zip(features, np.round(importances,2)))\n",
    "feature_importance.sort(key=lambda x:x[1], reverse = True)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the feature importances\n",
    "features_ranked = list(zip(*feature_importance))[0]\n",
    "feat_imp_ranked = list(zip(*feature_importance))[1]\n",
    "\n",
    "fig = plt.figure(figsize = [15,5])\n",
    "plt.xticks(fontsize = 14, rotation=75)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.xlabel('Plane Feature', fontsize = 18)\n",
    "plt.ylabel('Feature Importance', fontsize = 18)\n",
    "plt.bar(features_ranked, feat_imp_ranked, align='center');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sci-kit learn's feature importance uses `MeanDecreaseGini`, which measures the extent to which each variable plays a role in partitioning the data into the defined classes.\n",
    "\n",
    "As seen in the news article analysis, the `steer1` and `steer2` variables, quantifying the frequency of turning hard to the left, were the most important to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity \n",
    "\n",
    "Try training a model with a limited amout of features and see how the metrics change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add different columns based on feature importance here\n",
    "\n",
    "X_limited = planes_labeled[['steer1', ]] #add other features here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#factorize the class\n",
    "y = pd.factorize(planes_labeled['class'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test sets\n",
    "X_train_lim, X_test_lim, y_train, y_test = train_test_split(X_limited, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model based on the hyperparameters from the above grid search\n",
    "np.random.seed(415)\n",
    "model_tuned = RandomForestClassifier(n_estimators=1100, max_depth=50, max_features='sqrt', \n",
    "                                     min_samples_split=4, bootstrap=False, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model with only features above\n",
    "model_tuned.fit(X_train_lim, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions_tuned = model_tuned.predict(X_test_lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics\n",
    "precision_tuned = metrics.precision_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "recall_tuned = metrics.recall_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "accuracy_tuned = metrics.accuracy_score(y_true = y_test, y_pred = predictions_tuned)\n",
    "print('Randomized Grid Search Metrics: Precision: ' + str(precision_tuned) + ' Recall: ' + str(recall_tuned) + \n",
    "      ' Accuracy: ' + str(accuracy_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
